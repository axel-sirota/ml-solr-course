# Bonus Lab: FineTuning DistillBERT
## RankNet

In this notebook we will fine-tune DistillBERT, a transformer based on BERT Googles model
1- cd into the base of the repo
2- Run `jupyter notebook` from there (**not** the exercise folder of the lab!) and access the notebook in this lab, under `exercise`. Follow the instructions. Good luck!

Note: You can always check at the solutions!
