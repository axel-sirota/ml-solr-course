{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pysolr\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case your sys.path does not contain the base repo, cd there.\n",
    "print(sys.path)\n",
    "%cd '~/ml-solr-course'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_path = '3-query-generation/lab6/alternative_queries'\n",
    "query = 'Midtown sunny two bedroom'\n",
    "alternative_queries_model = tf.saved_model.load(model_path)\n",
    "print(f'Model loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create a client instance.\n",
    "solr = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Search 100 results for the query\n",
    "non_expanded_results = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for result in non_expanded_results:\n",
    "    i +=1\n",
    "    if i == 10:\n",
    "        break\n",
    "    print(f'The Neighborhood is {result[\"neighbourhood_cleansed\"]} and title is {result[\"name\"]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = None\n",
    "next_char = tf.constant([query])\n",
    "alternative_query = []\n",
    "\n",
    "for n in range(75):\n",
    "  next_char, states = None, None # Get the next character as before in the previous lab using the one_step_model\n",
    "  alternative_query.append(next_char)\n",
    "\n",
    "print(tf.strings.join(alternative_query)[0].numpy().decode(\"utf-8\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Join to form the laternative query\n",
    "new_query = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "new_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "expanded_results = None  # Search for the new expanded query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for result in expanded_results:\n",
    "    i +=1\n",
    "    if i == 10:\n",
    "        break\n",
    "    print(f'The Neighborhood is {result[\"neighbourhood_cleansed\"]} and title is {result[\"name\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Until now, we have used the text generation model to create a query based on the one we inputted and the model itself\n",
    "\n",
    "Now we will analyze the similarity of the query with both results, to see if we won something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '2-ranking/lab4/airbnb_model'\n",
    "doc2vec_model = Doc2Vec.load(model_path)\n",
    "print(f'Doc2Vec Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# As in lab5, tokenize both queries with gensim\n",
    "tokenized_query = None\n",
    "tokenized_new_query = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_new_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_non_expanded_results = pd.DataFrame(non_expanded_results)\n",
    "similarities = []\n",
    "for result in non_expanded_results:\n",
    "    similarity = 0 # Get the similarity between the query and the description in the result\n",
    "    similarities.append(similarity)\n",
    "df_non_expanded_results[\"Similarity\"] = pd.Series(similarities)\n",
    "\n",
    "# Order the result by similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_expanded_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Most similar document before expansion has description: \\n\\n{df_non_expanded_results[\"description\"].iloc[0]}\\nWith similarity: {df_non_expanded_results[\"Similarity\"].iloc[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_expanded_results = pd.DataFrame(expanded_results)\n",
    "new_similarities = []\n",
    "for result in expanded_results:\n",
    "    similarity = 0 # Get the similarity between the query and the description in the result of the expanded query\n",
    "    new_similarities.append(similarity)\n",
    "df_expanded_results[\"Similarity\"] = pd.Series(new_similarities)\n",
    "# Order the  expanded result by similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Most similar document after expansion has description: \\n\\n{df_expanded_results[\"description\"].iloc[0]}\\nWith similarity: {df_expanded_results[\"Similarity\"].iloc[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Number of documents that surpass 0.5 similarity threshold: {len(df_expanded_results[df_expanded_results[\"Similarity\"] >= 0.5])}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can tell that it appears we haven't won anything, but this was a model trained in 15 minutes. You quickly start to understand the structure of the training corpus and expand to more useful queries.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}