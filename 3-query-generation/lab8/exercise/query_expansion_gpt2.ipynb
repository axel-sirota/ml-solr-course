{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pysolr\n",
    "from gensim.models import Doc2Vec\n",
    "from transformers import pipeline, set_seed\n",
    "set_seed(42)\n",
    "np.random.seed(42)\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case your sys.path does not contain the base repo, cd there.\n",
    "print(sys.path)\n",
    "%cd '~/ml-solr-course'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Use the pipeline method to invoke the text-generation solution with gpt-2 as model.\n",
    "generator = None\n",
    "query = 'Midtown sunny two bedroom'\n",
    "expanded_queries = None #  Generate 10 possible expansions of 50 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '2-ranking/lab4/airbnb_model'\n",
    "doc2vec_model = Doc2Vec.load(model_path)\n",
    "print(f'Doc2Vec Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = []\n",
    "# For each possible expansion, get the similarity with the original query and get the best\n",
    "for expanded_query in expanded_queries:\n",
    "    pass\n",
    "expanded_query = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create a client instance.\n",
    "solr = pysolr.Solr('http://localhost:8983/solr/airbnb', always_commit=True, timeout=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "non_expanded_results = solr.search(query, **{\n",
    "                'rows': 100,\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "expanded_results = solr.search(expanded_query, **{\n",
    "                'rows': 100,\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Tokenize both the query, get the similarities with both the expanded and not expanded results in the pandas dataframe as always\n",
    "tokenized_query = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_non_expanded_results = pd.DataFrame(non_expanded_results)\n",
    "# Fill\n",
    "df_non_expanded_results.sort_values(by=\"Similarity\", ascending=False, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Most similar document before expansion has description: \\n\\n{df_non_expanded_results[\"description\"].iloc[0]}\\n\\nWith similarity: {df_non_expanded_results[\"Similarity\"].iloc[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_expanded_results = pd.DataFrame(expanded_results)\n",
    "# Fill\n",
    "df_expanded_results.sort_values(by=\"Similarity\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Most similar document after expansion has description: \\n\\n{df_expanded_results[\"description\"].iloc[0]}\\n\\nWith similarity: {df_expanded_results[\"Similarity\"].iloc[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Number of documents that surpass 0.5 similarity threshold: {len(df_expanded_results[df_expanded_results[\"Similarity\"] >= 0.5])}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "So it was useless? A key part of our models is that they are trained with our data. I leave you as exercise to see how much it improves if you finetune gpt-2 with a simple dense layer and train that over our airbnb dataset.\n",
    "\n",
    "Other problem to fix is that our airbnb similarity model is based on our airbnb data, but gpt-2 is generic. We should evaluate word similarity in the same terms, with the glove vectors alone instead. I leave it to you as exercise to see how much that changes as well.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}